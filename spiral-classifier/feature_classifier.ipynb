{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Feature Classifier (using VGG16 or ResNet50)<center>\n",
    "\n",
    "- This file aims to replicate the process done in [*Parkinson Disease Identification using Residual Networks and OPF* by Passos et al.](../Literature/dataset-papers/Passos_etal_22.pdf)\n",
    "- Use pretrained models to extract features from dataset \n",
    "- This is done by importing pretrained model (either VGG16 or ResNet50) and excluding the top layers (fully connected layers).\n",
    "- After the extracted features are caculated, can run these through as inputs through a global average pooling layer and FC layer to get classification output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "# import ML/DL libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils # used to shuffle data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator # used for image augmentation\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "# used for building and training a new model\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.applications import VGG16, ResNet50\n",
    "\n",
    "# import functions from other python files\n",
    "from code_files.imagePreprocessing import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV_ML\n",
      "Requirement already satisfied: pandas in /home/sagan/miniconda3/envs/ENV_ML/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/sagan/miniconda3/envs/ENV_ML/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sagan/miniconda3/envs/ENV_ML/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sagan/miniconda3/envs/ENV_ML/lib/python3.10/site-packages (from pandas) (1.23.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/sagan/miniconda3/envs/ENV_ML/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (161) does not match length of index (19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         testLbls \u001b[38;5;241m=\u001b[39m lbl\n\u001b[0;32m---> 43\u001b[0m         \u001b[43mtestImgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m img_path\n\u001b[1;32m     44\u001b[0m         testImgs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lblName\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# shuffle the data\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ENV_ML/lib/python3.10/site-packages/pandas/core/frame.py:3977\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3976\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3977\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ENV_ML/lib/python3.10/site-packages/pandas/core/frame.py:4171\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4162\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4163\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4169\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4171\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4174\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4175\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4176\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4177\u001b[0m     ):\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/ENV_ML/lib/python3.10/site-packages/pandas/core/frame.py:4904\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4904\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ENV_ML/lib/python3.10/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (161) does not match length of index (19)"
     ]
    }
   ],
   "source": [
    "# import images (and labels) and store in dataframe\n",
    "#data_path = 'datasets/folador_spiral/'  #'datasets/folador_spiral/'  \n",
    "data_path = 'datasets/handPD_HT/'\n",
    "\n",
    "trainImgs = pd.DataFrame()\n",
    "testImgs  = pd.DataFrame()\n",
    "trainArray = []\n",
    "testArray  = []\n",
    "\n",
    "\n",
    "for dataType in os.listdir(data_path):\n",
    "    img_path = []\n",
    "    lbl = []\n",
    "    lblName = []\n",
    "    for group in os.listdir(os.path.join(data_path, dataType)):\n",
    "        for img in os.listdir(os.path.join(data_path, dataType, group)):\n",
    "            path = os.path.join(data_path, dataType, group, img)\n",
    "            img_path.append(path) \n",
    "\n",
    "            # convert the image and store as a matrix\n",
    "            drawing = cv2.imread(path)\n",
    "            drawing = cv2.resize(drawing, (256,256))\n",
    "\n",
    "            if dataType == 'test':\n",
    "                testArray.append(drawing)\n",
    "            else:\n",
    "                trainArray.append(drawing)\n",
    "\n",
    "            # store the labels\n",
    "            if group == 'healthy':\n",
    "                lbl.append(0)\n",
    "                lblName.append('healthy')\n",
    "            else:\n",
    "                lbl.append(1)\n",
    "                lblName.append('parkinsons')\n",
    "\n",
    "    if dataType == 'train':\n",
    "        trainLbls = lbl\n",
    "        trainImgs['image'] = img_path\n",
    "        trainImgs['label'] = lblName\n",
    "    else:\n",
    "        testLbls = lbl\n",
    "        testImgs['image'] = img_path\n",
    "        testImgs['label'] = lblName\n",
    "\n",
    "# shuffle the data\n",
    "trainImgs, trainArray, trainLbls = utils.shuffle(trainImgs, trainArray, trainLbls)\n",
    "# testImgs, testArray, testLbls = utils.shuffle(testImgs, testArray, testLbls)\n",
    "\n",
    "# convert labels to categorical for training model\n",
    "trainLbls_categorical = tf.keras.utils.to_categorical(trainLbls)\n",
    "print(\"Lables of first 5 images: \\n\", trainLbls_categorical[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first five images\n",
    "print(\"Lables of first train 5 images: \", trainLbls[0:5])\n",
    "trainImgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test labels: \", testLbls)\n",
    "display(testImgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Extract features using pretrained model <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the convolutional base network for VGG16\n",
    "# output of this will be feature vectors for each image\n",
    "VGG16_conv_base = VGG16(weights='imagenet', include_top=False,input_shape=(256,256,3)) # setting include_top=False removes the fully connected layers of the model\n",
    "VGG16_conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will extract the features from conv network\n",
    "def extract_features(imgs, num_imgs):\n",
    "    datagen = ImageDataGenerator(rescale=1./255) # define to rescale pixels in image\n",
    "    batch_size = 10\n",
    "    \n",
    "    features = np.zeros(shape=(num_imgs, 8,8,512)) # shape equal to output of convolutional base\n",
    "    lbls = np.zeros(shape=(num_imgs,2))\n",
    "\n",
    "    # preprocess data\n",
    "    generator = datagen.flow_from_dataframe(imgs, x_col = 'image', y_col='label', target_size=(256,256), class_mode='categorical', batch_size=batch_size)\n",
    "\n",
    "    # Pass data through convolutional base\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = VGG16_conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        lbls[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= num_imgs:\n",
    "            break\n",
    "    return features, lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 validated image filenames belonging to 2 classes.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,8,8,512) into shape (10,8,8,512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# extract features for both the trainImgs and testImgs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#train_feat, train_lbls = extract_features(trainImgs, 240)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m test_feat, test_lbls \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestImgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(imgs, num_imgs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs_batch, labels_batch \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m     15\u001b[0m     features_batch \u001b[38;5;241m=\u001b[39m VGG16_conv_base\u001b[38;5;241m.\u001b[39mpredict(inputs_batch)\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m features_batch\n\u001b[1;32m     17\u001b[0m     lbls[i \u001b[38;5;241m*\u001b[39m batch_size: (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size] \u001b[38;5;241m=\u001b[39m labels_batch\n\u001b[1;32m     18\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,8,8,512) into shape (10,8,8,512)"
     ]
    }
   ],
   "source": [
    "# extract features for both the trainImgs and testImgs\n",
    "#train_feat, train_lbls = extract_features(trainImgs, 240)\n",
    "test_feat, test_lbls = extract_features(testImgs, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(240, 8, 8, 512) (240, 2)\n"
     ]
    }
   ],
   "source": [
    "var1 = train_feat; var2 = train_lbls\n",
    "print(type(var1), type(var2))\n",
    "print(np.shape(var1), np.shape(var2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on VGG16 classifier (using cross validation)\n",
    "# define a function that will fit the model\n",
    "def defineModel(size): # size is the dimension of the last layer in the pretrained model\n",
    "    model = Sequential()\n",
    "    model.add(GlobalAveragePooling2D(input_shape=(size,size,512)))\n",
    "    # global average pooling is used instead of fully connected layers on top of the feature maps\n",
    "    # it takes the average of each feature map and the resulting layer is fed directly into the softmax layer\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    # model.summary()\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)  # use the Adam optimizer and set an effective learning rate \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = defineModel(8)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using cross validation\n",
    "# will start with k-fold cross validation, taking 80% as training each fold\n",
    "\n",
    "# define model checkpoint callback\n",
    "model_chkpt = tf.keras.callbacks.ModelCheckpoint('20221007_VGG16_kfold_folDS_spiral_2.h5', verbose=0, save_best_only=True)\n",
    "\n",
    "def fit_and_evaluate(train_feat, train_lbls, val_feat, val_lbls, test_feat, test_lbls, epochs):\n",
    "    model = None\n",
    "    model = defineModel(8)\n",
    "    trained_model = model.fit(train_feat, train_lbls, batch_size=10, epochs=epochs, validation_data=(val_feat, val_lbls), callbacks=model_chkpt, verbose=0)\n",
    "\n",
    "    # testScore = model.evaluate(test_feat, test_lbls)\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with k-fold validation\n",
    "model_history = []\n",
    "epochs = 250\n",
    "\n",
    "num_val_samples = int(np.ceil(len(trainArray) * 0.20))\n",
    "k = int(np.floor(len(trainArray) / num_val_samples))\n",
    "\n",
    "for i in range(k):\n",
    "    print(\"Training on fold K = \", i+1)\n",
    "    startPt = i * num_val_samples\n",
    "    endPt   = (i+1) * num_val_samples\n",
    "\n",
    "    val_x = train_feat[startPt:endPt]\n",
    "    val_y = train_lbls[startPt:endPt]\n",
    "    train_x = np.delete(train_feat, np.linspace(startPt, endPt-1, num_val_samples).astype(np.int), axis=0)\n",
    "    train_y = np.delete(train_lbls, np.linspace(startPt, endPt-1, num_val_samples).astype(np.int), axis=0)\n",
    "\n",
    "    model_history.append(fit_and_evaluate(train_x, train_y, val_x, val_y, test_feat, test_lbls, epochs=epochs))\n",
    "    # print(model_history)\n",
    "    \n",
    "    print(\"=======\"*12, end=\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss functions for each fold\n",
    "color = ['blue', 'black', 'red', 'green','orange', 'cyan', 'grey', 'yellow', 'fuchsia']\n",
    "f, ax = plt.subplots(2, k, figsize=(35,6))\n",
    "for i in range(k):\n",
    "    ax[0][i].plot(model_history[i].history['accuracy'], label='train acc', color=color[i])\n",
    "    ax[0][i].plot(model_history[i].history['val_accuracy'], label='val acc', linestyle= ':', color=color[i])\n",
    "    ax[0][i].axis([-10,epochs, .2, 1.1])\n",
    "    ax[0][i].legend()\n",
    "\n",
    "    subplot_title = 'k = ' + str(i+1)\n",
    "    ax[0][i].title.set_text(subplot_title)\n",
    "\n",
    "for i in range(k):\n",
    "    ax[1][i].plot(model_history[i].history['loss'], label='train loss', color=color[i])\n",
    "    ax[1][i].plot(model_history[i].history['val_loss'], label='val loss', linestyle= ':', color=color[i])\n",
    "    ax[1][i].axis([-10,epochs, .0, 1.1])\n",
    "    ax[1][i].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "#                             LOAD PRE-EXISTING MODEL MODEL\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def importModel(filename, testAug, testAugLabel):\n",
    "    modelPath = 'savedModels/saved_h5_models/' + filename\n",
    "    testModel = tf.keras.models.load_model(modelPath)\n",
    "\n",
    "    loss, acc = testModel.evaluate(np.array(testAug), testAugLabel, verbose=2)\n",
    "    print(\"Loss: \", loss, \"| Accuracy: \", acc)\n",
    "\n",
    "    return testModel\n",
    "\n",
    "# load existing model and evaluate the test data\n",
    "testmodel = importModel('20221007_VGG16_kfold_handPD.h5', test_feat, test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMisclassImgs(testModel, test_feat, test_label, test_array):\n",
    "    test_label = np.array(test_label)\n",
    "    incorrectImgs = []\n",
    "    incorrectImgIdx = []\n",
    "\n",
    "    count = 0\n",
    "    fig, axes = plt.subplots(3, 8, figsize=(20,8))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(test_array, axes):\n",
    "        ax.imshow(np.squeeze(img), cmap=\"gray\") # plot image\n",
    "\n",
    "        # use the model to predict the label\n",
    "        predImg = testModel.predict(np.expand_dims(test_feat[count], axis=0), verbose=0) # use for grayscale\n",
    "        # predImg = testModel.predict(test_feat[count])                       # use for RGB\n",
    "        predLabel = np.argmax(predImg[0])       \n",
    "        \n",
    "        if test_label[count] != predLabel:\n",
    "            ax.set_title('Label: ' + str(test_label[count]) + ' | Pred: ' + str(predLabel), color='red')\n",
    "            # save off image to array\n",
    "            incorrectImgs.append(test_array[count])\n",
    "            incorrectImgIdx.append(count)\n",
    "        else:\n",
    "            ax.set_title('Label: ' + str(test_label[count]) + ' | Pred: ' + str(predLabel), color = 'blue')  \n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return np.array(incorrectImgs), np.array(incorrectImgIdx), testModel.predict(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "misClass_test, misClass_idx, predictions = plotMisclassImgs(testmodel, test_feat, np.argmax(test_lbls, axis=1), testArray)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# -----------------------------------------\n",
    "# -----------------------------------------\n",
    "# -----------------------------------------\n",
    "# other option for displaying accuracy and loss - plot them all overlaid\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Accuracies vs Epochs')\n",
    "for i in range(k):\n",
    "    plt.plot(model_history[i].history['accuracy'], label=i, color=color[i])\n",
    "    plt.plot(model_history[i].history['val_accuracy'], label=i, linestyle= 'dashdot', color=color[i])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Loss vs Epochs')\n",
    "for i in range(k):\n",
    "    plt.plot(model_history[i].history['loss'], label=i, color=color[i])\n",
    "    plt.plot(model_history[i].history['val_loss'], label=i, linestyle= 'dashdot', color=color[i])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e234cb3a6d44168381e6f6673d50d0e52fa65a6fba8cecddf6f45db9097571d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
