{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"permanent\" folders with the train, validation, and test data\n",
    "\n",
    "Train the model on this ONCE and then continue to use the same test data until everything is working. Then also only need to train the center detector once as well. \n",
    "\n",
    "Once everything is working, can work on retraining the model for repeatability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils # used to shuffle data\n",
    "\n",
    "from code_files.imagePreprocessing import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of labels:  102\n",
      "total number of images:  102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>datasets/Spiral_DataSet1_relabelled\\parkinsons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>datasets/Spiral_DataSet1_relabelled\\parkinsons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>datasets/Spiral_DataSet1_relabelled\\healthy\\V5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>datasets/Spiral_DataSet1_relabelled\\healthy\\V5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>datasets/Spiral_DataSet1_relabelled\\healthy\\V0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               images  label\n",
       "61  datasets/Spiral_DataSet1_relabelled\\parkinsons...      1\n",
       "72  datasets/Spiral_DataSet1_relabelled\\parkinsons...      1\n",
       "51  datasets/Spiral_DataSet1_relabelled\\healthy\\V5...      0\n",
       "81  datasets/Spiral_DataSet1_relabelled\\healthy\\V5...      0\n",
       "53  datasets/Spiral_DataSet1_relabelled\\healthy\\V0...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the images and create a dataframe containing the image path locations and their associated labels\n",
    "df = importImages('datasets/Spiral_DataSet1_relabelled')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation samples:  15\n",
      "total testing samples:  16\n",
      "total training samples:  71\n"
     ]
    }
   ],
   "source": [
    "# randomly split data in train and validation subsets (70-30 split)\n",
    "# stratify attempts to keep the labels 50-50 in the validation data (i.e. 7 total 0's and 8 total 1's)\n",
    "train_feature, val_feature, train_label, val_label = train_test_split(df['images'], df['label'], test_size=0.30, stratify=df['label'])\n",
    "\n",
    "# shuffle data\n",
    "train_feature, train_label = utils.shuffle(train_feature, train_label)\n",
    "val_feature, val_label = utils.shuffle(val_feature, val_label)\n",
    "\n",
    "## (OPTIONAL) split validation data into validation and testing data\n",
    "val_feature, test_feature, val_label, test_label = train_test_split(val_feature, val_label, test_size=0.5, stratify=val_label)\n",
    "\n",
    "# sort the test array so that all healthy images are first and PD images are last\n",
    "# this is useful for later when plotting\n",
    "testDF = pd.DataFrame(columns = ['img', 'lbl'])\n",
    "testDF['img'] = test_feature\n",
    "testDF['lbl'] = test_label\n",
    "testDF = testDF.sort_values('lbl')\n",
    "\n",
    "test_feature = testDF['img']\n",
    "test_label   = testDF['lbl']\n",
    "\n",
    "print(\"total validation samples: \", len(val_label))\n",
    "print(\"total testing samples: \", len(test_label))\n",
    "print('total training samples: ', len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the data sets (train, val, and test), convert from rgb to grayscale\n",
    "# then convert to an array of pixels [0-255] --> this returns an array of size (256,256,1)\n",
    "# resize to (128x128) for faster image processing and a more efficient model, data doesn't get lost in this resize\n",
    "# need to account for the batch dimension (used in tensorflow), so expand dim to shape (1,128,128,1)\n",
    "def img2array(dataset):\n",
    "    storage_array = []\n",
    "    for img_path in dataset:\n",
    "        openImg = PIL.Image.open(img_path)\n",
    "        image = openImg.convert(\"L\") # covert to grayscale (L), color use (P)\n",
    "        imgArray = np.array(image)\n",
    "        imgArray = cv2.resize(imgArray, (128,128))\n",
    "        imgArray = np.expand_dims(imgArray, axis=2) # if keeping rgb, use axis=0\n",
    "\n",
    "        # store in array\n",
    "        storage_array.append(imgArray)\n",
    "    \n",
    "    return storage_array\n",
    "\n",
    "train_array = img2array(train_feature)\n",
    "val_array   = img2array(val_feature)\n",
    "test_array  = img2array(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into folders in the dataset directory \n",
    "# parentDir = 'C:/Users/rebec/Documents/git-repos/hand-tremor-detection/hand-drawn-spiral-classifier-100patient/'\n",
    "val_pd_folder = 'datasets/val/pd/'\n",
    "val_h_folder = 'datasets/val/healthy/'\n",
    "test_pd_folder = 'datasets/test/pd/'\n",
    "test_h_folder = 'datasets/test/healthy/'\n",
    "\n",
    "for i in range(len(train_array)):\n",
    "    if train_label.iat[i] == 0: # if healthy, place in healthy folder\n",
    "        filename = 'datasets/spiral_data/train/healthy/' + 'train_h_' + str(i) + '.png'\n",
    "        img = Image.fromarray(np.squeeze(train_array[i]))\n",
    "        img.save(filename)\n",
    "    else: # place in pd folder\n",
    "        filename = 'datasets/spiral_data/train/pd/' + 'train_pd_' + str(i) + '.png'\n",
    "        img = Image.fromarray(np.squeeze(train_array[i]))\n",
    "        img.save(filename)\n",
    "\n",
    "for i in range(len(val_array)):\n",
    "    if val_label.iat[i] == 0: # if healthy, place in healthy folder\n",
    "        filename = 'datasets/spiral_data/val/healthy/' + 'val_h_' + str(i) + '.png'\n",
    "        img = Image.fromarray(np.squeeze(val_array[i]))\n",
    "        img.save(filename)\n",
    "    else: # place in pd folder\n",
    "        filename = 'datasets/spiral_data/val/pd/' + 'val_pd_' + str(i) + '.png'\n",
    "        img = Image.fromarray(np.squeeze(val_array[i]))\n",
    "        img.save(filename)\n",
    "\n",
    "for i in range(len(test_array)):\n",
    "    if test_label.iat[i] == 0: # if healthy, place in healthy folder\n",
    "        filename = 'datasets/spiral_data/test/healthy/' + 'test_h_' + str(i) + '.png'\n",
    "        img = Image.fromarray(np.squeeze(test_array[i]))\n",
    "        img.save(filename)\n",
    "    else: # place in pd folder\n",
    "        filename = 'datasets/spiral_data/test/pd/' + 'test_pd_' + str(i) + '.png'\n",
    "        img = Image.fromarray(np.squeeze(test_array[i]))\n",
    "        img.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MLEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e234cb3a6d44168381e6f6673d50d0e52fa65a6fba8cecddf6f45db9097571d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
