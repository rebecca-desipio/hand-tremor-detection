{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Keras and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns # statistical data visualization, used to plot total count for each label\n",
    "import random # used to split trainig and testing data\n",
    "import warnings\n",
    "import os # used to iterate through all the images in the specified directory\n",
    "\n",
    "# libraries used for loading images and visualization\n",
    "from keras.preprocessing.image import load_img\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# libraries to split the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import utils\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "# libraries to build the model\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "# image augmentation library \n",
    "import tensorflow_io as tfio\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiral_DataSet1_relabelled\\healthy\\V01HE02.png 0\n",
      "total number of labels:  102\n",
      "total number of images:  102\n",
      "                                                images  label\n",
      "0        Spiral_DataSet1_relabelled\\healthy\\V03HE2.png      0\n",
      "1       Spiral_DataSet1_relabelled\\healthy\\V08HE02.png      0\n",
      "2    Spiral_DataSet1_relabelled\\parkinsons\\V01PE03.png      1\n",
      "3       Spiral_DataSet1_relabelled\\healthy\\V55HE08.png      0\n",
      "4       Spiral_DataSet1_relabelled\\healthy\\V09HE01.png      0\n",
      "..                                                 ...    ...\n",
      "97   Spiral_DataSet1_relabelled\\parkinsons\\V06PE02.png      1\n",
      "98   Spiral_DataSet1_relabelled\\parkinsons\\V05PE03.png      1\n",
      "99      Spiral_DataSet1_relabelled\\healthy\\V05HE03.png      0\n",
      "100  Spiral_DataSet1_relabelled\\parkinsons\\V09PE03.png      1\n",
      "101  Spiral_DataSet1_relabelled\\parkinsons\\V06PE01.png      1\n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM8ElEQVR4nO3df6ydhV3H8feHFoK6TcBea0e3lTiC4o+h3CDbjAngFH8NXJBsbq4qSU2cukWjon/4Y3FmxM1JcJo0wiiKG8hEcH9sksq2zBC2243Jj46ABByk0Dt+BDCZWvb1j/vU3bX3tqfQ55yW7/uV3Nznx3nO+ZI07/vw3HOfk6pCktTHMbMeQJI0XYZfkpox/JLUjOGXpGYMvyQ1s3bWA0xi3bp1tWnTplmPIUlHlR07dnylqub23X5UhH/Tpk0sLCzMegxJOqokeWil7V7qkaRmDL8kNWP4JakZwy9JzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGaOir/cPRzO/O1rZj2CjjA7/uztsx4BgP989/fNegQdgV75B3eO9tyjhj/Jg8AzwHPAnqqaT3IScB2wCXgQuLiqnhxzDknS103jUs85VXVGVc0P65cC26vqVGD7sC5JmpJZXOO/ANg2LG8DLpzBDJLU1tjhL+BfkuxIsmXYtr6qdg3LjwLrVzowyZYkC0kWFhcXRx5TkvoY+5e7P1xVjyT5duCWJF9avrOqKkmtdGBVbQW2AszPz6/4GEnSoRv1jL+qHhm+7wZuBM4CHkuyAWD4vnvMGSRJ32i08Cf5liQv3bsM/BhwF3AzsHl42GbgprFmkCTtb8xLPeuBG5PsfZ2/r6qPJ/kccH2SS4CHgItHnEGStI/Rwl9VDwCvWWH748B5Y72uJOnAvGWDJDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmDL8kNWP4JakZwy9JzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Mzo4U+yJskXknxsWD8lye1J7k9yXZLjxp5BkvR10zjjfyewc9n6ZcAHqurVwJPAJVOYQZI0GDX8STYCPwX8zbAe4FzghuEh24ALx5xBkvSNxj7j/wvgd4CvDevfBjxVVXuG9YeBk1c6MMmWJAtJFhYXF0ceU5L6GC38SX4a2F1VO57P8VW1tarmq2p+bm7uME8nSX2tHfG5Xw+8MclPAscDLwMuB05IsnY4698IPDLiDJKkfYx2xl9Vv1dVG6tqE/Bm4F+r6q3ArcBFw8M2AzeNNYMkaX+zeB//7wK/meR+lq75XzmDGSSprTEv9fy/qvok8Mlh+QHgrGm8riRpf/7lriQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmDL8kNWP4JakZwy9JzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZkYLf5Ljk3w2yReT3J3kj4ftpyS5Pcn9Sa5LctxYM0iS9jfmGf9/A+dW1WuAM4Dzk5wNXAZ8oKpeDTwJXDLiDJKkfYwW/lry7LB67PBVwLnADcP2bcCFY80gSdrfqNf4k6xJcgewG7gF+A/gqaraMzzkYeDkVY7dkmQhycLi4uKYY0pSK6OGv6qeq6ozgI3AWcB3HcKxW6tqvqrm5+bmxhpRktqZKPxJtk+ybTVV9RRwK/Ba4IQka4ddG4FHJn0eSdILd8DwD+/MOQlYl+TEJCcNX5tY5RLNsmPnkpwwLH8T8AZgJ0s/AC4aHrYZuOmF/SdIkg7F2oPs/xXgXcDLgR1Ahu1PA395kGM3ANuSrGHpB8z1VfWxJPcAH0nyJ8AXgCuf5+ySpOfhgOGvqsuBy5P8elVdcShPXFX/DvzACtsfYOl6vyRpBg52xg9AVV2R5HXApuXHVNU1I80lSRrJROFP8rfAdwJ3AM8Nmwsw/JJ0lJko/MA8cHpV1ZjDSJLGN+n7+O8CvmPMQSRJ0zHpGf864J4kn2XpHjwAVNUbR5lKkjSaScP/R2MOIUmanknf1fOpsQeRJE3HpO/qeYald/EAHMfSnTb/q6peNtZgkqRxTHrG/9K9y0kCXACcPdZQkqTxHPLdOYf77P8T8OOHfxxJ0tgmvdTzpmWrx7D0vv6vjjKRJGlUk76r52eWLe8BHmTpco8k6Sgz6TX+Xxp7EEnSdEz6QSwbk9yYZPfw9dEkG8ceTpJ0+E36y90PATezdF/+lwP/PGyTJB1lJg3/XFV9qKr2DF9XA34QriQdhSYN/+NJ3pZkzfD1NuDxMQeTJI1j0vD/MnAx8Ciwi6XPzP3FkWaSJI1o0rdzvhvYXFVPAgwfwP4+ln4gSJKOIpOe8X//3ugDVNUTrPB5upKkI9+k4T8myYl7V4Yz/kn/b0GSdASZNN7vB25L8g/D+s8B7xlnJEnSmCb9y91rkiwA5w6b3lRV94w3liRpLBNfrhlCb+wl6Sh3yLdlliQd3Qy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaGS38SV6R5NYk9yS5O8k7h+0nJbklyX3D9xMP9lySpMNnzDP+PcBvVdXpwNnAO5KcDlwKbK+qU4Htw7okaUpGC39V7aqqzw/LzwA7gZOBC4Btw8O2AReONYMkaX9TucafZBNLt3G+HVhfVbuGXY8C66cxgyRpyejhT/IS4KPAu6rq6eX7qqqAWuW4LUkWkiwsLi6OPaYktTFq+JMcy1L0r62qfxw2P5Zkw7B/A7B7pWOramtVzVfV/Nycn+suSYfLmO/qCXAlsLOq/nzZrpuBzcPyZuCmsWaQJO1vzE/Rej3wC8CdSe4Ytv0+8F7g+iSXAA+x9CHukqQpGS38VfUZIKvsPm+s15UkHZh/uStJzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmDL8kNWP4JakZwy9JzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqZnRwp/kqiS7k9y1bNtJSW5Jct/w/cSxXl+StLIxz/ivBs7fZ9ulwPaqOhXYPqxLkqZotPBX1aeBJ/bZfAGwbVjeBlw41utLklY27Wv866tq17D8KLB+tQcm2ZJkIcnC4uLidKaTpAZm9svdqiqgDrB/a1XNV9X83NzcFCeTpBe3aYf/sSQbAIbvu6f8+pLU3rTDfzOweVjeDNw05deXpPbGfDvnh4HbgNOSPJzkEuC9wBuS3Af86LAuSZqitWM9cVW9ZZVd5431mpKkg/MvdyWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmDL8kNWP4JakZwy9JzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmDL8kNTOT8Cc5P8m9Se5PcuksZpCkrqYe/iRrgA8CPwGcDrwlyenTnkOSuprFGf9ZwP1V9UBV/Q/wEeCCGcwhSS2tncFrngx8edn6w8AP7fugJFuALcPqs0nuncJsXawDvjLrIWYt79s86xG0P/9t7vWHORzP8qqVNs4i/BOpqq3A1lnP8WKUZKGq5mc9h7Qv/21Oxywu9TwCvGLZ+sZhmyRpCmYR/s8BpyY5JclxwJuBm2cwhyS1NPVLPVW1J8mvAZ8A1gBXVdXd056jOS+h6Ujlv80pSFXNegZJ0hT5l7uS1Izhl6RmDH8j3ipDR6okVyXZneSuWc/SgeFvwltl6Ah3NXD+rIfowvD34a0ydMSqqk8DT8x6ji4Mfx8r3Srj5BnNImmGDL8kNWP4+/BWGZIAw9+Jt8qQBBj+NqpqD7D3Vhk7geu9VYaOFEk+DNwGnJbk4SSXzHqmFzNv2SBJzXjGL0nNGH5JasbwS1Izhl+SmjH8ktSM4Zf2keTZg+zfdKh3kUxydZKLXthk0uFh+CWpGcMvrSLJS5JsT/L5JHcmWX4307VJrk2yM8kNSb55OObMJJ9KsiPJJ5JsmNH40qoMv7S6rwI/W1U/CJwDvD9Jhn2nAX9VVd8NPA38apJjgSuAi6rqTOAq4D0zmFs6oLWzHkA6ggX40yQ/AnyNpdtYrx/2fbmq/m1Y/jvgN4CPA98L3DL8fFgD7JrqxNIEDL+0urcCc8CZVfW/SR4Ejh/27Xuvk2LpB8XdVfXa6Y0oHTov9Uir+1Zg9xD9c4BXLdv3yiR7A//zwGeAe4G5vduTHJvke6Y6sTQBwy+t7lpgPsmdwNuBLy3bdy/wjiQ7gROBvx4+0vIi4LIkXwTuAF433ZGlg/PunJLUjGf8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjP/Bx6KwKkBMivwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## --------------------------------------------------------\n",
    "#                  Create the Dataframe\n",
    "## --------------------------------------------------------\n",
    "img_path = [] # store image paths for all images (all images are size 256x256)\n",
    "label = [] # healthy (0) vs parkinsons (1)\n",
    "dataset_folder = 'Spiral_DataSet1_relabelled'\n",
    "\n",
    "# iterate through all of the images to create a binary array corresponding to the image labels\n",
    "for labeled_folder in os.listdir(dataset_folder):\n",
    "    for img in os.listdir(dataset_folder + \"/\" + labeled_folder):\n",
    "        if labeled_folder == 'healthy':\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(1)\n",
    "        img_path.append(os.path.join(dataset_folder, labeled_folder, img))\n",
    "\n",
    "# total number of images and labels should match\n",
    "print(img_path[1], label[1])\n",
    "print(\"total number of labels: \", len(label))\n",
    "print(\"total number of images: \", len(img_path))\n",
    "\n",
    "# now create the dataframe\n",
    "df = pd.DataFrame()\n",
    "df['images'] = img_path\n",
    "df['label']  = label\n",
    "\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True) # randomize the images, rather than having them be in order\n",
    "\n",
    "print(df)\n",
    "\n",
    "# show the total count for each of the labels\n",
    "sns.countplot(df['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pause\n"
     ]
    }
   ],
   "source": [
    "## -----------------------------------------------------------\n",
    "#               Split into test and training data\n",
    "## -----------------------------------------------------------\n",
    "#randomly split data in train and test subsets\n",
    "x_feature, val_feature, x_label, val_label = train_test_split(df['images'], df['label'], test_size=0.2, shuffle=False)\n",
    "\n",
    "# train, test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# shuffle data\n",
    "x_feature, x_label = utils.shuffle(x_feature, x_label)\n",
    "val_feature, val_label = utils.shuffle(val_feature, val_label)\n",
    "\n",
    "print(\"pause\")\n",
    "# convert y-col to str for binary class_mode\n",
    "# train['label'] = train['label'].astype('str')\n",
    "# test['label']  = test['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pause\n"
     ]
    }
   ],
   "source": [
    "## ------------------------------------------\n",
    "#       Convert images to raw pixels\n",
    "## ------------------------------------------\n",
    "train_array = []\n",
    "val_array = []\n",
    "\n",
    "for img_path in x_feature:\n",
    "    openImg = PIL.Image.open(img_path)\n",
    "    image = openImg.convert(\"P\") # covert to grayscale\n",
    "    imgArray = np.array(image)\n",
    "    imgArray = np.expand_dims(imgArray, axis=2)\n",
    "\n",
    "    # store in array\n",
    "    train_array.append(imgArray)\n",
    "\n",
    "for img_path in val_feature:\n",
    "    openImg = PIL.Image.open(img_path)\n",
    "    image = openImg.convert(\"L\") # covert to grayscale\n",
    "    imgArray = np.array(image)\n",
    "    imgArray = np.expand_dims(imgArray, axis=2)\n",
    "\n",
    "    # store in array\n",
    "    val_array.append(imgArray)\n",
    "\n",
    "\n",
    "print(\"pause\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pause\n",
      "pause\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------------------------------------\n",
    "#       Artificially create more images for a bigger dataset\n",
    "## -------------------------------------------------------------------\n",
    "# normalize the data\n",
    "train_gen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    rotation_range=360,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[.4,1.4],\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    rotation_range=360,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[.4,1.4],\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "## add more training images\n",
    "trainAug = []\n",
    "trainAugLabel = []\n",
    "\n",
    "for (i,v) in enumerate(x_label):\n",
    "    #print(\"i: \", i)\n",
    "    #print(\"v: \", v)\n",
    "    tempImg = np.expand_dims(train_array[i], axis=0)\n",
    "    aug = train_gen.flow(tempImg, batch_size=1, shuffle=True)\n",
    "    for addImages in range(50):\n",
    "        augImg = next(aug)[0].astype('uint8')\n",
    "        if np.size(augImg) == 256**2:\n",
    "            trainAug.append(augImg)\n",
    "            trainAugLabel.append(v)\n",
    "\n",
    "## add more validation images\n",
    "testAug = []\n",
    "testAugLabel = []\n",
    "\n",
    "for (i,v) in enumerate(val_label):\n",
    "    #print(\"i: \", i)\n",
    "    #print(\"v: \", v)\n",
    "    tempImg = np.expand_dims(val_array[i], axis=0)\n",
    "    aug = test_gen.flow(tempImg, batch_size=1)\n",
    "    for addImages in range(50):\n",
    "        augImg = next(aug)[0].astype('uint8')\n",
    "        if np.size(augImg) == 256**2:\n",
    "            testAug.append(augImg)\n",
    "            testAugLabel.append(v)\n",
    "\n",
    "print(\"pause\")\n",
    "\n",
    "# convert everything to numpy arrays (CNN does not like lists)\n",
    "# trainAug = np.array(trainAug)\n",
    "# testAug = np.array(testAug)\n",
    "\n",
    "#trainAug = train_array + trainAug\n",
    "#testAug = val_array + testAug\n",
    "\n",
    "trainAugLabel = np.array(trainAugLabel)\n",
    "testAugLabel = np.array(testAugLabel)\n",
    "\n",
    "\n",
    "print(\"pause\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "sns.countplot(trainAugLabel)\n",
    "plt.show()\n",
    "sns.countplot(testAugLabel)\n",
    "plt.show()\n",
    "\n",
    "print(np.round(len(testAug)/len(trainAug),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        #newImg=tf.image.rgb_to_hsv(img)\n",
    "        ax.imshow(img, cmap=\"gray\")       # applies a colormap by default      \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [testAug[0][0][i] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot images\n",
    "imfile = Image.fromarray(np.squeeze(testAug[2]))\n",
    "imfile.show(imfile)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------------------------------------------\n",
    "#                       Build the Model\n",
    "## -----------------------------------------------------------\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(256,256,1)),\n",
    "    MaxPool2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.1),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "'''\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "'''\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "## Train the model\n",
    "trained_model = model.fit(np.array(trainAug), trainAugLabel, epochs=50, validation_data=(np.array(testAug), testAugLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 256, 256, 128)     3328      \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 83, 83, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 83, 83, 64)        204864    \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 26, 26, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 26, 26, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 11, 11, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 5, 5, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                51264     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,298\n",
      "Trainable params: 287,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rebecca\\Documents\\Virginia_Tech\\SP22\\Research\\git-repos\\hand-tremor-detection\\hand-drawn-spiral-classifier-100patients\\spiral_image_classifier.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rebecca/Documents/Virginia_Tech/SP22/Research/git-repos/hand-tremor-detection/hand-drawn-spiral-classifier-100patients/spiral_image_classifier.ipynb#ch0000017?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rebecca/Documents/Virginia_Tech/SP22/Research/git-repos/hand-tremor-detection/hand-drawn-spiral-classifier-100patients/spiral_image_classifier.ipynb#ch0000017?line=22'>23</a>\u001b[0m \u001b[39m## Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rebecca/Documents/Virginia_Tech/SP22/Research/git-repos/hand-tremor-detection/hand-drawn-spiral-classifier-100patients/spiral_image_classifier.ipynb#ch0000017?line=23'>24</a>\u001b[0m trained_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49marray(trainAug), trainAugLabel, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(np\u001b[39m.\u001b[39;49marray(testAug), testAugLabel))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1126'>1127</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1127'>1128</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1128'>1129</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1129'>1130</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Rebecca/anaconda3/envs/MLenv/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1130'>1131</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\Rebecca\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "reg = tf.keras.regularizers.l2(0.001)\n",
    "opt = tf.keras.optimizers.Adam(epsilon=3.15e-5)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(128, (5,5), padding='same', strides=(1,1), activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=reg, input_shape=(256,256,1)),\n",
    "    MaxPool2D((9,9), strides=(3,3)),\n",
    "    Conv2D(64, (5,5), padding='same', strides=(1,1), activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=reg),\n",
    "    MaxPool2D((7,7), strides=(3,3)),\n",
    "    Conv2D(32, (3,3), padding='same', strides=(1,1), activation='relu',kernel_initializer ='glorot_uniform', kernel_regularizer=reg),\n",
    "    MaxPool2D((5,5), strides=(2,2)),\n",
    "    Conv2D(32, (3,3), padding='same', strides=(1,1), activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=reg),\n",
    "    MaxPool2D((3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu', kernel_initializer='glorot_uniform'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2,activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "## Train the model\n",
    "trained_model = model.fit(np.array(trainAug), trainAugLabel, epochs=50, validation_data=(np.array(testAug), testAugLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------------------------------------------\n",
    "#                       Plot the Results\n",
    "## -----------------------------------------------------------\n",
    "# Accuracy and Validation Accuracy\n",
    "accuracy = trained_model.history['accuracy']\n",
    "val_acc = trained_model.history['val_accuracy']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.figure()\n",
    "\n",
    "# Loss and Validation Loss\n",
    "loss = trained_model.history['loss']\n",
    "val_loss = trained_model.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be06593c2f7c6c659d27d21530649fc496370ea6abbb7431f6c1d3f2c07b5e69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MLenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
