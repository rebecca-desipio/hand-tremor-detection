{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Keras and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns # statistical data visualization, used to plot total count for each label\n",
    "import random # used to split trainig and testing data\n",
    "import warnings\n",
    "import os # used to iterate through all the images in the specified directory\n",
    "import cv2\n",
    "\n",
    "# libraries used for loading images and visualization\n",
    "from keras.preprocessing.image import load_img\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# libraries to split the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import utils\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "# libraries to build the model\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Input\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiral_DataSet1_relabelled\\healthy\\V01HE02.png 0\n",
      "total number of labels:  102\n",
      "total number of images:  102\n",
      "                                               images  label\n",
      "47     Spiral_DataSet1_relabelled\\healthy\\V09HE03.png      0\n",
      "54  Spiral_DataSet1_relabelled\\parkinsons\\V09PE02.png      1\n",
      "94  Spiral_DataSet1_relabelled\\parkinsons\\V11PE01.png      1\n",
      "95      Spiral_DataSet1_relabelled\\healthy\\V03HE2.png      0\n",
      "14     Spiral_DataSet1_relabelled\\healthy\\V08HE02.png      0\n",
      "..                                                ...    ...\n",
      "24     Spiral_DataSet1_relabelled\\healthy\\V05HE01.png      0\n",
      "70  Spiral_DataSet1_relabelled\\parkinsons\\V11PE02.png      1\n",
      "38  Spiral_DataSet1_relabelled\\parkinsons\\V10PE03.png      1\n",
      "3   Spiral_DataSet1_relabelled\\parkinsons\\V07PE01.png      1\n",
      "20     Spiral_DataSet1_relabelled\\healthy\\V11HE02.png      0\n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## --------------------------------------------------------\n",
    "#                  Create the Dataframe\n",
    "## --------------------------------------------------------\n",
    "img_path = [] # store image paths for all images (all images are size 256x256)\n",
    "label = [] # healthy (0) vs parkinsons (1)\n",
    "dataset_folder = 'Spiral_DataSet1_relabelled'\n",
    "\n",
    "# iterate through all of the images to create a binary array corresponding to the image labels\n",
    "for labeled_folder in os.listdir(dataset_folder):\n",
    "    for img in os.listdir(dataset_folder + \"/\" + labeled_folder):\n",
    "        if labeled_folder == 'healthy':\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(1)\n",
    "        img_path.append(os.path.join(dataset_folder, labeled_folder, img))\n",
    "\n",
    "# total number of images and labels should match\n",
    "print(img_path[1], label[1])\n",
    "print(\"total number of labels: \", len(label))\n",
    "print(\"total number of images: \", len(img_path))\n",
    "\n",
    "# now create the dataframe\n",
    "df = pd.DataFrame()\n",
    "df['images'] = img_path\n",
    "df['label']  = label\n",
    "\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True) # randomize the images, rather than having them be in order\n",
    "df = utils.shuffle(df)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# show the total count for each of the labels\n",
    "sns.countplot(df['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# validation samples:  16\n",
      "# testing samples:  16\n",
      "# training samples:  70\n",
      "pause\n"
     ]
    }
   ],
   "source": [
    "## -----------------------------------------------------------\n",
    "#               Split into test and training data\n",
    "## -----------------------------------------------------------\n",
    "#randomly split data in train and test subsets\n",
    "x_feature, val_feature, x_label, val_label = train_test_split(df['images'], df['label'], test_size=0.31, stratify=df['label'])\n",
    "\n",
    "# shuffle data\n",
    "#x_feature, x_label = utils.shuffle(x_feature, x_label)\n",
    "val_feature, val_label = utils.shuffle(val_feature, val_label)\n",
    "\n",
    "## (OPTIONAL) split val and test data\n",
    "val_feature, test_feature, val_label, test_label = train_test_split(val_feature, val_label, test_size=0.5, shuffle=False)\n",
    "\n",
    "print(\"# validation samples: \", len(val_label))\n",
    "print(\"# testing samples: \", len(test_label))\n",
    "print('# training samples: ', len(x_label))\n",
    "\n",
    "print(\"pause\")\n",
    "# convert y-col to str for binary class_mode\n",
    "# train['label'] = train['label'].astype('str')\n",
    "# test['label']  = test['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76    0\n",
      "30    0\n",
      "97    1\n",
      "21    1\n",
      "15    1\n",
      "64    1\n",
      "22    0\n",
      "72    0\n",
      "9     0\n",
      "41    0\n",
      "14    0\n",
      "93    1\n",
      "69    1\n",
      "86    1\n",
      "60    1\n",
      "57    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pause\n"
     ]
    }
   ],
   "source": [
    "## ------------------------------------------\n",
    "#       Convert images to raw pixels\n",
    "## ------------------------------------------\n",
    "train_array = []\n",
    "val_array = []\n",
    "\n",
    "for img_path in x_feature:\n",
    "    openImg = PIL.Image.open(img_path)\n",
    "    image = openImg.convert(\"P\") # covert to grayscale\n",
    "    imgArray = np.array(image)\n",
    "    imgArray = cv2.resize(imgArray, (128,128))\n",
    "    imgArray = np.expand_dims(imgArray, axis=2)\n",
    "\n",
    "    # store in array\n",
    "    train_array.append(imgArray)\n",
    "\n",
    "for img_path in val_feature:\n",
    "    openImg = PIL.Image.open(img_path)\n",
    "    image = openImg.convert(\"L\") # covert to grayscale\n",
    "    imgArray = np.array(image)\n",
    "    imgArray = cv2.resize(imgArray, (128,128))\n",
    "    imgArray = np.expand_dims(imgArray, axis=2)\n",
    "\n",
    "    # store in array\n",
    "    val_array.append(imgArray)\n",
    "\n",
    "\n",
    "print(\"pause\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pause\n",
      "pause\n"
     ]
    }
   ],
   "source": [
    "## -------------------------------------------------------------------\n",
    "#       Artificially create more images for a bigger dataset\n",
    "## -------------------------------------------------------------------\n",
    "# normalize the data\n",
    "train_gen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    rotation_range=360,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[.4,1.4],\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    rotation_range=360,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[.4,1.4],\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "## add more training images\n",
    "trainAug = []\n",
    "trainAugLabel = []\n",
    "\n",
    "for (i,v) in enumerate(x_label):\n",
    "    #print(\"i: \", i)\n",
    "    #print(\"v: \", v)\n",
    "    tempImg = np.expand_dims(train_array[i], axis=0)\n",
    "    aug = train_gen.flow(tempImg, batch_size=1, shuffle=True)\n",
    "    for addImages in range(80):\n",
    "        augImg = next(aug)[0].astype('uint8')\n",
    "        if np.size(augImg) == 128**2:\n",
    "            trainAug.append(augImg)\n",
    "            trainAugLabel.append(v)\n",
    "\n",
    "## add more validation images\n",
    "valAug = []\n",
    "valAugLabel = []\n",
    "\n",
    "for (i,v) in enumerate(val_label):\n",
    "    #print(\"i: \", i)\n",
    "    #print(\"v: \", v)\n",
    "    tempImg = np.expand_dims(val_array[i], axis=0)\n",
    "    aug = test_gen.flow(tempImg, batch_size=1)\n",
    "    for addImages in range(40):\n",
    "        augImg = next(aug)[0].astype('uint8')\n",
    "        if np.size(augImg) == 128**2:\n",
    "            valAug.append(augImg)\n",
    "            valAugLabel.append(v)\n",
    "\n",
    "print(\"pause\")\n",
    "\n",
    "trainAugLabel = tf.keras.utils.to_categorical(np.array(trainAugLabel))\n",
    "valAugLabel = tf.keras.utils.to_categorical(np.array(valAugLabel))\n",
    "\n",
    "\n",
    "print(\"pause\")\n",
    "\n",
    "# shuffle data\n",
    "trainAug, trainAugLabel = utils.shuffle(trainAug, trainAugLabel)\n",
    "valAug, valAugLabel = utils.shuffle(valAug, valAugLabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAE/CAYAAAB4j2SfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAftElEQVR4nO3df5TddX3n8eeroLRWKihTCklo2DZui9uKbop0dXeptPKj7Ua7loVuJaXsxrbQ1T12t+huC8XS2l2VLa1LGw8pwVURf62pm61FtOW4R5RgKZJQD6OCSRpg5LdSaYPv/eN+Bi4xmcxM5jN3JvN8nHPP/d7P9/P93vedk3zyync+9/NNVSFJkiRpbn3bqAuQJEmSDkYGbUmSJKkDg7YkSZLUgUFbkiRJ6sCgLUmSJHVg0JYkSZI6MGjroJfkj5L8xlz3PVBJ7kry4/PxXpI0aklOSbJj6PXWJKdMp+8s3mtexvIDrVMHv0NHXYA0lSR3Af+uqj4+23NU1S/16DufkhSwqqrGR12LJM2FqnrBXJwnyS8w+HfiZUPnXnBj+d7q1MHPK9pa1JL4n0VJkrQgGbS1YCV5F3Ac8KdJvpbkPydZmaSSnJ/kK8AnWt/3J7knycNJbkzygqHzXJ3kt9v2KUl2JHlDkvuS7Epy3iz7Pi/JnyZ5JMnNSX47yaem+DyvSXJ3kvuT/Jc99p2U5NNJHmrv84dJntn23di6/XX7OfybJEcm+WiSiSQPtu3lB/ozl6SpJPn1JB/Yo+33k1zRts9LckeSR5N8KclrpzjXk9PnknxHG38fTLIN+JE9+l6U5IvtvNuSvKq1/yDwR8CPtvHxodb+5FjeXv/7JONJHkiyKcmxQ/sqyS8lubONwe9Ikn3UPNd1/mSSv2r/jmxPcskUP34tQgZtLVhV9RrgK8BPV9Wzq+q/De3+l8APAqe11/8XWAV8N/A54N1TnPp7gOcAy4DzgXckOXIWfd8BfL31Wdsee5XkBOBK4DXAscDzgOFg/ATwH4GjgB8FTgV+pf0c/kXr88L2c3gfg7+7fwJ8L4P/jPwd8IdTfGZJmgvXAmcmORwgySHAWcB72v77gJ8Cvgs4D7g8yYuncd6Lge9rj9P41vH0i8A/ZzAe/xbwv5IcU1V3AL8EfLqNj0fseeIkLwd+t9V5DHB3+xzDfopBaP7h1u809m6u6/w6cC5wBPCTwC8neeU+3luLkEFbi9UlVfX1qvo7gKraUFWPVtXjwCXAC5M8Zx/H/gNwaVX9Q1VtBr4G/OOZ9G3/uPxr4OKqeqyqtgEbp6j31cBHq+rGVuNvAN+c3FlVt1TVTVW1u6ruAv6YwX8m9qqq7q+qD7b3fhS4bKr+kjQXqupuBhczXtWaXg48VlU3tf3/p6q+WAN/Cfw5g+C5P2cBl1XVA1W1Hbhij/d9f1X9bVV9s11suBM4aZpl/1tgQ1V9ro2/b2RwZXnlUJ+3VNVDVfUV4JPAifNRZ1X9RVV9vvW/DXgvjuUHFYO2FqvtkxtJDknylvbrukeAu9quo/Zx7P1VtXvo9WPAs2fYd4zBl4m3D+0b3t7TscP7q+rrwP1Dn+H5bfrHPe0z/M4U9ZPkWUn+uE1FeQS4ETii/QdAknp6D3BO2/45nrqaTZIzktzUpmg8BJzJFGPZkKeNkQyuOj8pyblJbm1TOx4C/sk0zzt57ifPV1VfYzD+Lhvqc8/Q9lT/JsxpnUlekuSTbRrgwwyuek/3c2kRMGhroatptP8csAb4cQa/rlvZ2vc6x26OTAC7efr0jxVT9N81vD/JsxhMH5l0JfA3DFYW+S7gTUxd/xsYXIV/Ses/Ob2k52eWJID3A6e074W8iha0kxwGfBB4K3B0mx6xmemNS08bIxlMiaOd93uBdwIXAs9r57196Lz7+ndi0t8ymGY3eb7vZDD+7pxGXb3rfA+wCVhRVc9hMI/bcfwgYtDWQncv8I/20+dw4HEGVyiexeBqcFdV9QTwIeCSdnX5BxjMs9uXDwA/leRl7UuOl/L0v3+HA48AX2vn+uU9jt/z53A4g3nZDyV5LoN5g5LUXVVNAH/B4HsiX27zjwGeCRxGuxCR5AzgFdM87XXAG9sXvZcDvzq07zsZhNQJGHzhksGV4kn3Assnv0C+F+8FzktyYvvPwO8An2nT9GZqrus8HHigqr6R5CQGF450EDFoa6H7XeC/tl/D/do++lzD4Nd3O4FtwE3zVNuFDK6g3wO8i8Fg/vjeOlbVVuACBlcvdgEPAsM3Ofg1BgPsowyuiLxvj1NcAmxsP4ezgP8BfAfwVQaf98/m4gNJ0jS9h8FvEZ+cNtK+L/IfGITRBxmMaZumeb7fYjCOf5nBvO53DZ13G/A24NMMwuoPAf9v6NhPAFuBe5J8dc8Tt/sw/AaDq+27GHyR8exp1tW7zl8BLk3yKPCbDH52Ooikan+/cZE0HUl+D/ieqtrn6iOSJGnp8Iq2NEtJfiDJD2fgJAbL/3141HVJkqSFwbvqSbN3OIPpIscy+DXh24CPjLQiSZK0YDh1RJIkSerAqSOSJElSBwZtSZIkqYODco72UUcdVStXrhx1GZI0K7fccstXq2ps1HXMJ8dtSYvVVGP2QRm0V65cyZYtW0ZdhiTNSpK799/r4OK4LWmxmmrMduqIJEmS1IFBW5IkSerAoC1JkiR1YNCWJEmSOjBoS5IkSR0YtCVJkqQODNqSJElSBwZtSZIkqQODtiRJktSBQVuSJEnqwKAtSZIkdXDoqAtYiP7pf7pm1CWos1v++7kje++vXPpDI3tvzZ/jfvPzoy5hyXDMXhpGNW47Zi8NvcZsr2hLkiRJHRi0JUmSpA4M2pIkSVIHBm1JkiSpA4O2JEmS1IFBW5IkSerAoC1JkiR1YNCWJEmSOjBoS5IkSR0YtCVJkqQODNqSJElSBwZtSdKUknx7ks8m+eskW5P8Vms/PslnkowneV+SZ7b2w9rr8bZ/5Ug/gCSNiEFbkrQ/jwMvr6oXAicCpyc5Gfg94PKq+n7gQeD81v984MHWfnnrJ0lLjkFbkjSlGvhae/mM9ijg5cAHWvtG4JVte017Tdt/apLMT7WStHAYtCVJ+5XkkCS3AvcB1wNfBB6qqt2tyw5gWdteBmwHaPsfBp43rwVL0gJg0JYk7VdVPVFVJwLLgZOAHzjQcyZZl2RLki0TExMHejpJWnAM2pKkaauqh4BPAj8KHJHk0LZrObCzbe8EVgC0/c8B7t/LudZX1eqqWj02Nta7dEmadwZtSdKUkowlOaJtfwfwE8AdDAL3q1u3tcBH2vam9pq2/xNVVfNWsCQtEIfuv4skaYk7BtiY5BAGF2iuq6qPJtkGXJvkt4G/Aq5q/a8C3pVkHHgAOHsURUvSqBm0JUlTqqrbgBftpf1LDOZr79n+DeBn56E0SVrQnDoiSZIkdWDQliRJkjowaEuSJEkddAvaSVYk+WSSbUm2Jnlda78kyc4kt7bHmUPHvDHJeJIvJDltqP301jae5KJeNUuSJElzpeeXIXcDb6iqzyU5HLglyfVt3+VV9dbhzklOYPDN9BcAxwIfT/L8tvsdDJaT2gHcnGRTVW3rWLskSZJ0QLoF7araBexq248muYOnbs+7N2uAa6vqceDLbVmoyW+zj7dvt5Pk2tbXoC1JkqQFa17maCdZyWBpqM+0pguT3JZkQ5IjW9syYPvQYTta277aJUmSpAWre9BO8mzgg8Drq+oR4Erg+4ATGVzxftscvc+6JFuSbJmYmJiLU0qSJEmz1jVoJ3kGg5D97qr6EEBV3VtVT1TVN4F38tT0kJ3AiqHDl7e2fbU/TVWtr6rVVbV6bGxs7j+MJEmSNAM9Vx0Jg9vw3lFVbx9qP2ao26uA29v2JuDsJIclOR5YBXwWuBlYleT4JM9k8IXJTb3qliRJkuZCz1VHXgq8Bvh8kltb25uAc5KcCBRwF/BagKramuQ6Bl9y3A1cUFVPACS5EPgYcAiwoaq2dqxbkiRJOmA9Vx35FJC97No8xTGXAZftpX3zVMdJkiRJC413hpQkSZI6MGhLkiRJHRi0JUmSpA4M2pIkSVIHBm1JkiSpA4O2JEmS1IFBW5IkSerAoC1JkiR1YNCWJEmSOjBoS5IkSR0YtCVJkqQODNqSJElSBwZtSZIkqQODtiRJktSBQVuSJEnqwKAtSZIkdWDQliRJkjowaEuSJEkdGLQlSZKkDgzakiRJUgcGbUnSPiVZkeSTSbYl2Zrkda39kiQ7k9zaHmcOHfPGJONJvpDktNFVL0mjdeioC5AkLWi7gTdU1eeSHA7ckuT6tu/yqnrrcOckJwBnAy8AjgU+nuT5VfXEvFYtSQuAV7QlSftUVbuq6nNt+1HgDmDZFIesAa6tqser6svAOHBS/0olaeExaEuSpiXJSuBFwGda04VJbkuyIcmRrW0ZsH3osB1MHcwl6aBl0JYk7VeSZwMfBF5fVY8AVwLfB5wI7ALeNotzrkuyJcmWiYmJuSxXkhYEg7YkaUpJnsEgZL+7qj4EUFX3VtUTVfVN4J08NT1kJ7Bi6PDlre1bVNX6qlpdVavHxsb6fQBJGhGDtiRpn5IEuAq4o6rePtR+zFC3VwG3t+1NwNlJDktyPLAK+Ox81StJC4mrjkiSpvJS4DXA55Pc2treBJyT5ESggLuA1wJU1dYk1wHbGKxYcoErjkhaqgzakqR9qqpPAdnLrs1THHMZcFm3oiRpkXDqiCRJktSBQVuSJEnqwKAtSZIkdWDQliRJkjowaEuSJEkdGLQlSZKkDgzakiRJUgcGbUmSJKmDbkE7yYokn0yyLcnWJK9r7c9Ncn2SO9vzka09Sa5IMp7ktiQvHjrX2tb/ziRre9UsSZIkzZWeV7R3A2+oqhOAk4ELkpwAXATcUFWrgBvaa4AzgFXtsQ64EgbBHLgYeAlwEnDxZDiXJEmSFqpuQbuqdlXV59r2o8AdwDJgDbCxddsIvLJtrwGuqYGbgCOSHAOcBlxfVQ9U1YPA9cDpveqWJEmS5sK8zNFOshJ4EfAZ4Oiq2tV23QMc3baXAduHDtvR2vbVLkmSJC1Y3YN2kmcDHwReX1WPDO+rqgJqjt5nXZItSbZMTEzMxSklSZKkWesatJM8g0HIfndVfag139umhNCe72vtO4EVQ4cvb237an+aqlpfVauravXY2NjcfhBJkiRphnquOhLgKuCOqnr70K5NwOTKIWuBjwy1n9tWHzkZeLhNMfkY8IokR7YvQb6itUmSJEkL1qEdz/1S4DXA55Pc2treBLwFuC7J+cDdwFlt32bgTGAceAw4D6CqHkjyZuDm1u/SqnqgY92SJEnSAesWtKvqU0D2sfvUvfQv4IJ9nGsDsGHuqpMkSZL68s6QkiRJUgcGbUmSJKkDg7YkSZLUgUFbkiRJ6sCgLUmSJHVg0JYkSZI6MGhLkiRJHRi0JUmSpA4M2pIkSVIHBm1JkiSpA4O2JEmS1IFBW5IkSerAoC1JkiR1YNCWJEmSOjBoS5KmlGRFkk8m2ZZka5LXtfbnJrk+yZ3t+cjWniRXJBlPcluSF4/2E0jSaBi0JUn7sxt4Q1WdAJwMXJDkBOAi4IaqWgXc0F4DnAGsao91wJXzX7IkjZ5BW5I0paraVVWfa9uPAncAy4A1wMbWbSPwyra9BrimBm4CjkhyzPxWLUmjZ9CWJE1bkpXAi4DPAEdX1a626x7g6La9DNg+dNiO1iZJS4pBW5I0LUmeDXwQeH1VPTK8r6oKqBmeb12SLUm2TExMzGGlkrQwGLQlSfuV5BkMQva7q+pDrfneySkh7fm+1r4TWDF0+PLW9jRVtb6qVlfV6rGxsX7FS9KIGLQlSVNKEuAq4I6qevvQrk3A2ra9FvjIUPu5bfWRk4GHh6aYSNKSceioC5AkLXgvBV4DfD7Jra3tTcBbgOuSnA/cDZzV9m0GzgTGgceA8+a1WklaIAzakqQpVdWngOxj96l76V/ABV2LkqRFwKkjkiRJUgcGbUmSJKkDg7YkSZLUgUFbkiRJ6sCgLUmSJHVg0JYkSZI6MGhLkiRJHRi0JUmSpA4M2pIkSVIH0wraSW6YTpskaeFyLJek+TXlLdiTfDvwLOCoJEfy1C14vwtY1rk2SdIccCyXpNGYMmgDrwVeDxwL3MJTg/MjwB/2K0uSNIccyyVpBKYM2lX1+8DvJ/nVqvqDeapJkjSHHMslaTT2d0UbgKr6gyT/DFg5fExVXdOpLknSHHMsl6T5Nd0vQ74LeCvwMuBH2mP1fo7ZkOS+JLcPtV2SZGeSW9vjzKF9b0wynuQLSU4baj+9tY0nuWiGn0+S1MxmLJckzd60rmgzGIhPqKqawbmvZjD3b88rJZdX1VuHG5KcAJwNvIDBHMKPJ3l+2/0O4CeAHcDNSTZV1bYZ1CFJGpjNWC5JmqXprqN9O/A9MzlxVd0IPDDN7muAa6vq8ar6MjAOnNQe41X1par6e+Da1leSNHMzHsslSbM33SvaRwHbknwWeHyysar+1Sze88Ik5wJbgDdU1YMMlpe6aajPDp5acmr7Hu0vmcV7SpLmdiyXJO3HdIP2JXP0flcCbwaqPb8N+MW5OHGSdcA6gOOOO24uTilJB5tLRl2AJC0l01115C/n4s2q6t7J7STvBD7aXu4EVgx1Xd7amKJ9z3OvB9YDrF692vmHkrSHuRrLJUnTM91VRx5N8kh7fCPJE0kemembJTlm6OWrGMwXBNgEnJ3ksCTHA6uAzwI3A6uSHJ/kmQy+MLlppu8rSZq7sVySND3TvaJ9+OR2kjD4QuLJUx2T5L3AKQxu+bsDuBg4JcmJDKaO3MXgbmVU1dYk1wHbgN3ABVX1RDvPhcDHgEOADVW1dfofT5I0aTZjuSRp9qY7R/tJbVmo/53kYmCf61pX1Tl7ab5qiv6XAZftpX0zsHmmdUqS9m26Y7kkafamFbST/MzQy29jsBbrN7pUJEnqwrFckubXdK9o//TQ9m4G0z5cz1qSFhfHckmaR9Odo31e70IkSX05lkvS/JruqiPLk3w4yX3t8cEky3sXJ0maO47lkjS/pnsL9j9hsKzese3xp61NkrR4OJZL0jyabtAeq6o/qard7XE1MNaxLknS3HMsl6R5NN2gfX+Sn09ySHv8PHB/z8IkSXPOsVyS5tF0g/YvAmcB9wC7gFcDv9CpJklSH47lkjSPpru836XA2qp6ECDJc4G3Mhi0JUmLg2O5JM2j6V7R/uHJgRmgqh4AXtSnJElSJ7May5NsaKuU3D7UdkmSnUlubY8zh/a9Mcl4ki8kOW3OP4UkLRLTDdrfluTIyRftKsiMb98uSRqp2Y7lVwOn76X98qo6sT02t3OeAJwNvKAd8z+THHLAlUvSIjTdsPw24NNJ3t9e/yxwWZ+SJEmdzGosr6obk6yc5nusAa6tqseBLycZB04CPj2LeiVpUZvWFe2qugb4GeDe9viZqnpXz8IkSXOrw1h+YZLb2tSSySvly4DtQ312tLZvkWRdki1JtkxMTBxAGZK0ME17+kdVbQO2daxFktTZHI7lVwJvBqo9v40ZfqmyqtYD6wFWr15dc1CTJC0o052jLUnSk6rq3qp6oqq+CbyTwfQQgJ3AiqGuy1ubJC05Bm1J0owlOWbo5auAyRVJNgFnJzksyfHAKuCz812fJC0ErhwiSZpSkvcCpwBHJdkBXAyckuREBlNH7gJeC1BVW5Ncx2B6ym7ggqp6YgRlS9LIGbQlSVOqqnP20nzVFP0vw5WpJMmpI5IkSVIPBm1JkiSpA4O2JEmS1IFBW5IkSerAoC1JkiR1YNCWJEmSOjBoS5IkSR0YtCVJkqQODNqSJElSBwZtSZIkqQODtiRJktSBQVuSJEnqwKAtSZIkdWDQliRJkjowaEuSJEkdGLQlSZKkDgzakiRJUgcGbUmSJKkDg7YkSZLUgUFbkiRJ6qBb0E6yIcl9SW4fantukuuT3Nmej2ztSXJFkvEktyV58dAxa1v/O5Os7VWvJEmSNJd6XtG+Gjh9j7aLgBuqahVwQ3sNcAawqj3WAVfCIJgDFwMvAU4CLp4M55IkSdJC1i1oV9WNwAN7NK8BNrbtjcArh9qvqYGbgCOSHAOcBlxfVQ9U1YPA9XxreJckSZIWnPmeo310Ve1q2/cAR7ftZcD2oX47Wtu+2r9FknVJtiTZMjExMbdVS5IkSTM0si9DVlUBNYfnW19Vq6tq9djY2FydVpIkSZqV+Q7a97YpIbTn+1r7TmDFUL/lrW1f7ZIkSdKCNt9BexMwuXLIWuAjQ+3nttVHTgYeblNMPga8IsmR7UuQr2htkiRJ0oJ2aK8TJ3kvcApwVJIdDFYPeQtwXZLzgbuBs1r3zcCZwDjwGHAeQFU9kOTNwM2t36VVtecXLCVJkqQFp1vQrqpz9rHr1L30LeCCfZxnA7BhDkuTJEmSuvPOkJIkSVIHBm1JkiSpA4O2JGlKSTYkuS/J7UNtz01yfZI72/ORrT1JrkgynuS2JC8eXeWSNFoGbUnS/lzNt96V9yLghqpaBdzQXgOcAaxqj3XAlfNUoyQtOAZtSdKUqupGYM8Vn9YAG9v2RuCVQ+3X1MBNwBGT90+QpKXGoC1Jmo2j2/0OAO4Bjm7by4DtQ/12tDZJWnIM2pKkA9KWaK2ZHpdkXZItSbZMTEx0qEySRsugLUmajXsnp4S05/ta+05gxVC/5a3tW1TV+qpaXVWrx8bGuhYrSaNg0JYkzcYmYG3bXgt8ZKj93Lb6yMnAw0NTTCRpSel2Z0hJ0sEhyXuBU4CjkuwALgbeAlyX5HzgbuCs1n0zcCYwDjwGnDfvBUvSAmHQliRNqarO2ceuU/fSt4AL+lYkSYuDU0ckSZKkDgzakiRJUgcGbUmSJKkDg7YkSZLUgUFbkiRJ6sCgLUmSJHVg0JYkSZI6MGhLkiRJHRi0JUmSpA4M2pIkSVIHBm1JkiSpA4O2JEmS1IFBW5IkSerAoC1JkiR1YNCWJEmSOjBoS5IkSR0YtCVJkqQODNqSJElSBwZtSZIkqQODtiRJktSBQVuSJEnqwKAtSZIkdWDQliRJkjowaEuSJEkdGLQlSZKkDgzakiRJUgcjCdpJ7kry+SS3JtnS2p6b5Pokd7bnI1t7klyRZDzJbUlePIqaJUmSpJkY5RXtH6uqE6tqdXt9EXBDVa0CbmivAc4AVrXHOuDKea9UkiRJmqGFNHVkDbCxbW8EXjnUfk0N3AQckeSYEdQnSZIkTduognYBf57kliTrWtvRVbWrbd8DHN22lwHbh47d0dokSZKkBevQEb3vy6pqZ5LvBq5P8jfDO6uqktRMTtgC+zqA4447bu4qlSRJkmZhJFe0q2pne74P+DBwEnDv5JSQ9nxf674TWDF0+PLWtuc511fV6qpaPTY21rN8SZIkab/mPWgn+c4kh09uA68Abgc2AWtbt7XAR9r2JuDctvrIycDDQ1NMJEkjNJNVpCRpqRnF1JGjgQ8nmXz/91TVnyW5GbguyfnA3cBZrf9m4ExgHHgMOG/+S5YkTeHHquqrQ68nV5F6S5KL2utfH01pkjQ68x60q+pLwAv30n4/cOpe2gu4YB5KkyTNjTXAKW17I/AXGLQlLUELaXk/SdLiM5NVpJ4mybokW5JsmZiYmI9aJWlejWrVEUnSwWHWq0hV1XpgPcDq1atntNKUJC0GXtGWJM3aDFeRkqQlxaAtSZqVWawiJUlLilNHJEmzNdNVpCRpSTFoS5JmZaarSEnSUuPUEUmSJKkDg7YkSZLUgUFbkiRJ6sCgLUmSJHVg0JYkSZI6MGhLkiRJHRi0JUmSpA4M2pIkSVIHBm1JkiSpA4O2JEmS1IFBW5IkSerAoC1JkiR1YNCWJEmSOjBoS5IkSR0YtCVJkqQODNqSJElSBwZtSZIkqQODtiRJktSBQVuSJEnqwKAtSZIkdWDQliRJkjowaEuSJEkdGLQlSZKkDgzakiRJUgcGbUmSJKkDg7YkSZLUgUFbkiRJ6sCgLUmSJHVg0JYkSZI6MGhLkiRJHRi0JUmSpA4WTdBOcnqSLyQZT3LRqOuRJO2bY7YkLZKgneQQ4B3AGcAJwDlJThhtVZKkvXHMlqSBRRG0gZOA8ar6UlX9PXAtsGbENUmS9s4xW5JYPEF7GbB96PWO1iZJWngcsyUJOHTUBcyVJOuAde3l15J8YZT1LEJHAV8ddRHzJW9dO+oSlpol9ecLgItzIEd/71yVsZA5bh+QJfd3ynF7Xi25P1+9xuzFErR3AiuGXi9vbU+qqvXA+vks6mCSZEtVrR51HTo4+edrydnvmA2O2wfCv1PqyT9fc2exTB25GViV5PgkzwTOBjaNuCZJ0t45ZksSi+SKdlXtTnIh8DHgEGBDVW0dcVmSpL1wzJakgUURtAGqajOwedR1HMT89a168s/XEuOY3Z1/p9STf77mSKpq1DVIkiRJB53FMkdbkiRJWlQM2kvI/m6JnOSwJO9r+z+TZOUIytQilWRDkvuS3L6P/UlyRfvzdVuSF893jdJi47itXhyz54dBe4mY5i2RzwcerKrvBy4Hfm9+q9QidzVw+hT7zwBWtcc64Mp5qElatBy31dnVOGZ3Z9BeOqZzS+Q1wMa2/QHg1CQHtIK7lo6quhF4YIoua4BrauAm4Igkx8xPddKi5Litbhyz54dBe+mYzi2Rn+xTVbuBh4HnzUt1Wgq8Lbc0M47bGiXH7Dlg0JYkSZI6MGgvHdO5JfKTfZIcCjwHuH9eqtNSMK3bckt6kuO2Rskxew4YtJeO6dwSeROwtm2/GvhEudC65s4m4Nz2TfaTgYerateoi5IWMMdtjZJj9hxYNHeG1IHZ1y2Rk1wKbKmqTcBVwLuSjDP4gsTZo6tYi02S9wKnAEcl2QFcDDwDoKr+iMFdAs8ExoHHgPNGU6m0ODhuqyfH7PnhnSElSZKkDpw6IkmSJHVg0JYkSZI6MGhLkiRJHRi0JUmSpA4M2pIkSVIHBm1JkiSpA4O2JEmS1IFBW5IkSerg/wPSv8kWs1I1VQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training data samples:  5600\n",
      "Total validation data samples:  640\n",
      "Training-to-validation ratio:  11.0 %\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(12,5)\n",
    "ax0 = sns.countplot(trainAugLabel[:,1], ax=ax[0])\n",
    "ax0.title.set_text(\"training data\")\n",
    "ax1 = sns.countplot(valAugLabel[:,1], ax=ax[1])\n",
    "ax1.title.set_text(\"validation data\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Total training data samples: \", len(trainAug))\n",
    "print(\"Total validation data samples: \", len(valAug))\n",
    "print(\"Training-to-validation ratio: \", np.round(len(valAug)/len(trainAug),2)*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot images\n",
    "imgNum = 0 # insert number to view image\n",
    "imfile = Image.fromarray(np.squeeze(val_array[4]))\n",
    "imfile.show(imfile)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = tf.keras.regularizers.l2(0.001)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (5,5), padding='same', strides=(1,1), dilation_rate = 1, activation='relu', kernel_regularizer=reg, input_shape=(128,128,1)),\n",
    "    MaxPool2D((7,7), strides=(2,2)),\n",
    "    Conv2D(32, (5,5), padding='same', strides=(1,1), dilation_rate = 2, activation='relu', kernel_regularizer=reg),\n",
    "    MaxPool2D((5,5), strides=(2,2)),\n",
    "    Conv2D(64, (3,3), padding='same', strides=(1,1), dilation_rate = 1, activation='relu', kernel_regularizer=reg),\n",
    "    MaxPool2D((3,3), strides=(1,1)),\n",
    "    Conv2D(128, (3,3), padding='same', strides=(1,1), dilation_rate = 2, activation='relu', kernel_regularizer=reg),\n",
    "    MaxPool2D((3,3), strides=(1,1)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "## Train the model\n",
    "trained_model = model.fit(np.array(trainAug), np.array(trainAugLabel), batch_size=128, epochs=20, validation_data=(np.array(valAug), np.array(valAugLabel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------------------------------------------\n",
    "#                       Plot the Results\n",
    "## -----------------------------------------------------------\n",
    "# Accuracy and Validation Accuracy\n",
    "accuracy = trained_model.history['accuracy']\n",
    "val_acc = trained_model.history['val_accuracy']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.figure()\n",
    "\n",
    "# Loss and Validation Loss\n",
    "loss = trained_model.history['loss']\n",
    "val_loss = trained_model.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5,5), padding='same', strides=(1,1), dilation_rate = 1, activation=tf.keras.activations.LeakyReLU(alpha=0.1), kernel_regularizer=reg, input_shape=(128,128,1)))\n",
    "model.add(MaxPool2D((7,7), strides=(2,2)))\n",
    "model.add(Conv2D(64, (5,5), padding='same', strides=(1,1), dilation_rate = 1, activation=tf.keras.activations.LeakyReLU(alpha=0.1), kernel_regularizer=reg))\n",
    "model.add(MaxPool2D((3,3), strides=(2,2)))\n",
    "model.add(Conv2D(128, (3,3), padding='same', strides=(1,1), dilation_rate = 1, activation='relu', kernel_regularizer=reg))\n",
    "model.add(MaxPool2D((3,3), strides=(1,1)))\n",
    "model.add(Conv2D(256, (3,3), padding='same', strides=(1,1), dilation_rate = 2, activation='relu', kernel_regularizer=reg))\n",
    "model.add(MaxPool2D((3,3), strides=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------------------------------------------\n",
    "#                       Build the Model\n",
    "## -----------------------------------------------------------\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(256,256,1)),\n",
    "    MaxPool2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.1),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "'''\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "'''\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (5,5), padding='same', strides=(1,1), dilation_rate = 1, activation='relu', kernel_regularizer=reg, input_shape=(128,128,1)),\n",
    "    MaxPool2D((7,7), strides=(2,2)),\n",
    "    Conv2D(64, (5,5), padding='same', strides=(1,1), dilation_rate = 1, activation='relu', kernel_regularizer=reg),\n",
    "    MaxPool2D((3,3), strides=(2,2)),\n",
    "    Conv2D(128, (3,3), padding='same', strides=(1,1), dilation_rate = 1, activation='relu', kernel_regularizer=reg),\n",
    "    MaxPool2D((3,3), strides=(1,1)),\n",
    "    Conv2D(256, (3,3), padding='same', strides=(1,1), dilation_rate = 2, activation='relu', kernel_regularizer=reg),\n",
    "    MaxPool2D((3,3), strides=(1,1)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "## Train the model\n",
    "trained_model = model.fit(np.array(trainAug), trainAugLabel, epochs=50, validation_data=(np.array(testAug), testAugLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 128, 128, 128)     3328      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 40, 40, 64)        204864    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 12, 12, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238,146\n",
      "Trainable params: 238,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newModel = tf.keras.models.load_model(\"h5model.h5\")\n",
    "\n",
    "newModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 7s - loss: 96.9120 - accuracy: 0.7766 - 7s/epoch - 357ms/step\n",
      "0.776562511920929\n"
     ]
    }
   ],
   "source": [
    "loss, acc = newModel.evaluate(np.array(valAug), valAugLabel, verbose=2)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(val_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be06593c2f7c6c659d27d21530649fc496370ea6abbb7431f6c1d3f2c07b5e69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MLenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
